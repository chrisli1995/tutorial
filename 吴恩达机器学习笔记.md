吴恩达机器学习笔记

### 基本概念

1、监督学习可以理解为训练集已经告诉你要做什么（训练集存在标签），而无监督学习则没有告诉你要干嘛，需要机器自己找到训练集中的规律。例如分类是监督学习，而聚类是无监督学习。

2、回归问题=预测 

### 单变量逻辑回归

#### 代价函数（损失函数）

即只有一个输入的线性预测问题，我们的目标就是训练如下的函数h(x)中的$\theta$

![1524146940749](https://github.com/chrisli1995/photo/raw/master/markdown/1524146940749.png)

即让带进去的训练集（x，y）能很好的拟合到预测函数里面。做法是预测值与实际值的差距尽量的缩小。上列子中给了一个代价函数来表示他们之间的误差，这里的代价函数选用了平方误差代价函数，这是一个解决回归问题的常用手段。下图具体的操作。

![1524227586788](https://github.com/chrisli1995/photo/raw/master/markdown/1524227586788.png)

需要注意的是我们的预测函数是关于x的，而代价函数是关于$\theta$的函数。所以代价函数可以大致画成

![1524229823184](https://github.com/chrisli1995/photo/raw/master/markdown/1524229823184.png)

或者使用的等高线图来表示上面的3D图![1524230075600](https://github.com/chrisli1995/photo/raw/master/markdown/1524230075600.png)

可以从图中中心点代价函数值最小，即拟合训练集比较好。下面一章会讲如何找到使代价函数最小的参数$\theta$，即经典的梯度下降算法。







